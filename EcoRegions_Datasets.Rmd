---
title: "EcoRegion_Datasets"
author: "JT_Miller"
date: "3/14/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The purpose of this markdown is to create datasets for the analysis of the ecoregions. To do this:
1) Data from GBIF pull and AMNH will be read, cleaned, and combined into one dataset
2) The Taxize and left join will be used to resolve and replace errenous names
3) The resulting dataset will then be parsed out by each ecoregion and wrote to its own .csv

## Necessary Libraries
```{r}
library(sf)
library(tidyverse)
library(taxize)
library(leaflet)
library(sqldf)
```



## 1. Data pull from GBIF and AMNH
```{r}
# Read in the data from GBIF
specimen_data <- read.delim(file="D:/CCBER/Occurrence_Maps/Bee_diversity_research/Data/bee_catalogued.txt",header=TRUE)

# Remove data that does not have an associated genus or specificEpithet
specimen_complete <- specimen_data %>% 
  filter(!(genus == "")) %>% 
  filter(!(specificEpithet == ""))

# Unite the genus and specificEpithet column to give a scientific name
specimen_data_SN  <- specimen_complete %>% 
  unite(scientific_name, genus, specificEpithet, sep = " ")

# Remove any empty occurrenceIDs and keep only distinct values
specimen_occur_IDed <- specimen_data_SN %>%
  dplyr::filter(!(occurrenceID == "")) %>% 
  dplyr::distinct(occurrenceID, .keep_all = TRUE)

# Remove any empty catalogeNumbers and keep only distinct values
specimen_occur_IDed_CatalogNumbered <- specimen_occur_IDed %>% 
  dplyr::filter(!(catalogNumber == "")) %>% 
  dplyr::distinct(catalogNumber, .keep_all = TRUE)

# Read in the data from AMNH
AMNH_specimens <- read.delim(file = "D:/CCBER/Occurrence_Maps/Bee_diversity_research/Data/AMNH_occurrences.tab", header = TRUE)

# Check
AMNH_specimens_t <- AMNH_specimens %>% 
  distinct(occurrenceID, .keep_all = TRUE) # These are equivalent, therefore no cleaning is needed on this dataset

# Filter out any empty values for the same fields as the GBIF pull, and keep only distinct values for OccurID and CatalogNumber
AMNH_specimens_complete <- AMNH_specimens %>%
  filter(!(genus == "")) %>% 
  filter(!(specificEpithet == "")) %>% 
  dplyr::filter(!(occurrenceID == "")) %>% 
  dplyr::distinct(occurrenceID, .keep_all = TRUE) %>% 
  dplyr::filter(!(catalogNumber == "")) %>% 
  dplyr::distinct(catalogNumber, .keep_all = TRUE)

# Create a scientific name column
AMNH_specimens_data_SN_complete  <- AMNH_specimens_complete %>% 
  unite(scientific_name, genus, specificEpithet, sep = " ")

# Remove any columns that aren't comparable between the two datasets
AMNH_specimens_simplified <- AMNH_specimens_data_SN_complete %>% 
  select(institutionCode, basisOfRecord,occurrenceID, catalogNumber, eventDate, year, month, day, decimalLatitude, decimalLongitude, georeferenceVerificationStatus, scientificName, kingdom, phylum, class, order, family, scientific_name, subgenus)

specimen_occur_less<- specimen_occur_IDed_CatalogNumbered %>% 
  select(!institutionID)

combined_datasets_totals <- rbind(specimen_occur_less, AMNH_specimens_simplified) 

# NOTE: catalogNumber was again more inclusive, therefore the distinct was ran on it. 

combined_datasets_distinct_catalogNumber <- combined_datasets_totals %>% 
  dplyr::distinct(catalogNumber, .keep_all = TRUE) 
```

### 2. Taxize the data and Left join to find and replace taxonomic mistakes.
```{r}
# Make a variable that stores the sources that can be used in the global names database
sources <- gnr_datasources()

# Subset out the sources variable to only include the id for the Discover Life Bee Species Guide, set that to the variable 'Get_Disc_Life'
Get_Disc_Life <- sources$id[sources$title == 'Discover Life Bee Species Guide']

# Do the same thing but add ITIS as a second id
Get_Disc_Life_ITIS <- c(sources$id[sources$title == 'Discover Life Bee Species Guide'], sources$id[sources$title == 'Integrated Taxonomic Information SystemITIS'])

# 
unique_names <- combined_datasets_distinct_catalogNumber %>% 
  distinct(scientific_name, .keep_all = TRUE)

# Find the Corrected Names, use gnr_resolve to look at scientific name column and give resolved names based on the preferred source of Discover Life, and secondarily ITIS. Then change the scientific name to only include genus and specific Epithet using canonical = TRUE. 
Corrected_Names <- gnr_resolve(sci = unique_names$scientific_name, data_source_ids = Get_Disc_Life_ITIS, preferred_data_sources = Get_Disc_Life, resolve_once = TRUE, canonical = TRUE)

# Take Corrected_Names and remove any values for ____ that are 0.750 or below
Corrected_Names_r <- Corrected_Names %>% 
  filter(!(score == 0.750)) # Loses 38 Names that we are not confident in.

# Use a left join SQL query to correct the names in our dataset (THIS NEEDS TO BE UPDATED)
#  
left_joined_specimens <- sqldf("SELECT DISTINCT dataset.*, real_name_map.accepted_name
FROM combined_datasets_distinct_catalogNumber dataset 
LEFT JOIN (SELECT DISTINCT sub_dataset.scientific_name, MAX(sub_real_names.matched_name2) accepted_name
    FROM combined_datasets_distinct_catalogNumber sub_dataset
    LEFT JOIN Corrected_Names_r sub_real_names ON sub_dataset.scientific_name = sub_real_names.user_supplied_name
    GROUP BY sub_dataset.scientific_name) real_name_map ON dataset.scientific_name = real_name_map.accepted_name")


left_joined_specimens_dropped <- left_joined_specimens %>% 
  filter(!(is.na(accepted_name)))

```


### 3. The resulting dataset must be changed in a spatial type file and then parsed out to each ecoregion respectively. These Ecoregion Datasets will then be written to their own .csv files. 
```{r}
# Bring in 3rd level of Ecoregions by the EPA
eco_map <- sf::read_sf("filter_polygon/cali_ecoregions_3/ca_eco_l3.shp") %>% 
  sf::st_transform('+proj=longlat +datum=WGS84') 

colpal <- colorFactor(c("#00EDF4", "#F40000", "#D58400", "#139715", "#3740AE"), eco_map$L2_KEY)

colpal_ext <- colorFactor(c("#a6cee3", "#1f78b4", "#b2df8a", "#33a02c", "#fb9a99", "#e31a1c", "#fdbf6f", "#ff7f00", "#cab2d6", "#6a3d9a", "#ffff99", "#b15928"), eco_map$NA_L3NAME)

leaflet(eco_map) %>%
  addPolygons(stroke = FALSE, smoothFactor = 0.2, fillOpacity = 1,
              color = ~colpal_ext(NA_L3NAME)) %>% 
   addProviderTiles("Esri.WorldGrayCanvas") %>% 
  addLegend("bottomright", pal = colpal_ext, values = eco_map$NA_L3NAME)

# Remove anything without a lat lon coordinate 
bees_w_coords <- left_joined_specimens_dropped %>% 
  dplyr::filter(!is.na(decimalLatitude)|!is.na(decimalLongitude)) %>% 
  dplyr::filter(!(decimalLongitude == "")) %>% 
  dplyr::filter(!(decimalLatitude == ""))

bees_w_coords_w_crs <- st_as_sf(bees_w_coords, coords = c('decimalLongitude', 'decimalLatitude'), crs = 4326)

bees_bounded <- bees_w_coords_w_crs[eco_map,]

bees_bounded_sep <- bees_bounded %>%
  dplyr::mutate(decimalLatitude = sf::st_coordinates(.)[,2],
                decimalLongitude = sf::st_coordinates(.)[,1])



```

```{r}
### Parsing out the shapefiles 

#Seperating out the shapefile by ecoregions lvl 3
Coast_Range <- eco_map[1,]
Central_Basin_and_Range <- eco_map[2,]
Mojave_Basin_and_Range <- eco_map[3,]
Cascades <- eco_map[4,]
Sierra_Nevadas <- eco_map[5,]
Cali_Coastal_Sage_Chap_Oak_Woodlands1 <- eco_map[6,]
Central_Cali_Valley <- eco_map[7,]
Klamath_Mountains <- eco_map[8,]
Southern_and_Baja_Cali_PineOak_Mounts <- eco_map[9,]
Northern_Basin_and_Range <- eco_map[10,]
Sonoran_Desert <- eco_map[11,]
Cali_Coastal_Sage_Chap_Oak_Woodlands2 <- eco_map[12,]
Eastern_Cascades_Slopes_and_Foothills <- eco_map[13,]

# Subset the bees out by each of the ecoregion shapefiles
Coast_Range_Bees <- bees_bounded_sep[Coast_Range,]
Central_Basin_and_Range_Bees <- bees_bounded_sep[Central_Basin_and_Range,]
Mojave_Basin_and_Range_Bees <- bees_bounded_sep[Mojave_Basin_and_Range,]
Cascades_Bees <- bees_bounded_sep[Cascades,]
Sierra_Nevadas_Bees <- bees_bounded_sep[Sierra_Nevadas,]
Cali_Coastal_Sage_Chap_Oak_Woodlands1_Bees <- bees_bounded_sep[Cali_Coastal_Sage_Chap_Oak_Woodlands1,]
Central_Cali_Valley_Bees <- bees_bounded_sep[Central_Cali_Valley,]
Klamath_Mountains_Bees <- bees_bounded_sep[Klamath_Mountains,]
Southern_and_Baja_Cali_PineOak_Mounts_Bees <- bees_bounded_sep[Southern_and_Baja_Cali_PineOak_Mounts,]
Northern_Basin_and_Range_Bees <- bees_bounded_sep[Northern_Basin_and_Range,]
Sonoran_Desert_Bees <- bees_bounded_sep[Sonoran_Desert,]
Cali_Coastal_Sage_Chap_Oak_Woodlands2_Bees <- bees_bounded_sep[Cali_Coastal_Sage_Chap_Oak_Woodlands2,]
Eastern_Cascades_Slopes_and_Foothills_Bees <- bees_bounded_sep[Eastern_Cascades_Slopes_and_Foothills,]

#combining the Sage Chap Woodland regions since they are the same (?)
Cali_Coastal_Sage_Chap_Oak_Woodlands_Bees <- rbind(Cali_Coastal_Sage_Chap_Oak_Woodlands1_Bees, Cali_Coastal_Sage_Chap_Oak_Woodlands2_Bees)


```

# Write the Regions to their own .csv files 
```{r eval=FALSE, include=FALSE}
st_write(Coast_Range_Bees, "E:/CCBER/Occurrence_Maps/Bee_diversity_research/Outputs/EcoRegion_Bees/Coast_Range_Bees.csv",  layer_options = "GEOMETRY=AS_WKT")

st_write(Central_Basin_and_Range_Bees, "E:/CCBER/Occurrence_Maps/Bee_diversity_research/Outputs/EcoRegion_Bees/Central_Basin_and_Range_Bees.csv",  layer_options = "GEOMETRY=AS_WKT")

st_write(Mojave_Basin_and_Range_Bees, "E:/CCBER/Occurrence_Maps/Bee_diversity_research/Outputs/EcoRegion_Bees/Mojave_Basin_and_Range_Bees.csv",  layer_options = "GEOMETRY=AS_WKT")

st_write(Cascades_Bees, "E:/CCBER/Occurrence_Maps/Bee_diversity_research/Outputs/EcoRegion_Bees/Cascades_Bees.csv",  layer_options = "GEOMETRY=AS_WKT")

st_write(Sierra_Nevadas_Bees, "E:/CCBER/Occurrence_Maps/Bee_diversity_research/Outputs/EcoRegion_Bees/Sierra_Nevadas_Bees.csv",  layer_options = "GEOMETRY=AS_WKT")

st_write(Cali_Coastal_Sage_Chap_Oak_Woodlands_Bees, "E:/CCBER/Occurrence_Maps/Bee_diversity_research/Outputs/EcoRegion_Bees/Cali_Coastal_Sage_Chap_Oak_Woodlands_Bees.csv",  layer_options = "GEOMETRY=AS_WKT")

st_write(Central_Cali_Valley_Bees, "E:/CCBER/Occurrence_Maps/Bee_diversity_research/Outputs/EcoRegion_Bees/Central_Cali_Valley_Bees.csv",  layer_options = "GEOMETRY=AS_WKT")

st_write(Klamath_Mountains_Bees, "E:/CCBER/Occurrence_Maps/Bee_diversity_research/Outputs/EcoRegion_Bees/Klamath_Mountains_Bees.csv",  layer_options = "GEOMETRY=AS_WKT")

st_write(Southern_and_Baja_Cali_PineOak_Mounts_Bees, "E:/CCBER/Occurrence_Maps/Bee_diversity_research/Outputs/EcoRegion_Bees/Southern_and_Baja_Cali_PineOak_Mounts_Bees.csv",  layer_options = "GEOMETRY=AS_WKT")

st_write(Northern_Basin_and_Range_Bees, "E:/CCBER/Occurrence_Maps/Bee_diversity_research/Outputs/EcoRegion_Bees/Northern_Basin_and_Range_Bees.csv",  layer_options = "GEOMETRY=AS_WKT")

st_write(Sonoran_Desert_Bees, "E:/CCBER/Occurrence_Maps/Bee_diversity_research/Outputs/EcoRegion_Bees/Sonoran_Desert_Bees.csv",  layer_options = "GEOMETRY=AS_WKT")

st_write(Eastern_Cascades_Slopes_and_Foothills_Bees, "E:/CCBER/Occurrence_Maps/Bee_diversity_research/Outputs/EcoRegion_Bees/Eastern_Cascades_Slopes_and_Foothills_Bees.csv",  layer_options = "GEOMETRY=AS_WKT")
```

### Steps towards iNEXT, making an incidence dataframe.
```{r}
# First I need to create a Incidence dataframe that has the columns as each Ecoregion, and the rows as unique species found in all California.

regions <- unique(c(eco_map$NA_L3NAME))

print(regions)

unique_bee_names <- unique(c(bees_bounded_sep$accepted_name))

df <- data.frame(unique_bee_names, EcoRegions = regions)

print(df)
glimpse(df)

install.packages("fossil")
library(fossil)
create.matrix(df)
```
```{r}
#install.packages("vegan")
library(vegan)
#install.packages("reshape")
library(reshape)

Klamath_Mountains_Bees$ecoregion <- 'Klamath_Mountains' # Give the ecoregion a name
Klamath_Mountains_Bees$weighted_value <- 1 # Create a value as a place holder just to say 'Hey this is 1 bee'
Klamath_df <- as.data.frame(Klamath_Mountains_Bees) # Make it into a dataframe

melted_data <- melt(Klamath_df, id = c(names(Klamath_df))) # Melt the data frame so we can reshape it

site_reshaped <- reshape::cast(melted_data, accepted_name ~ ecoregion, value = 'weighted_value') # Reshape it 


test <- Klamath_Mountains_Bees %>% 
  filter(accepted_name == "Anthophora urbana") # Check it 

########################
decostand(Klamath_Mountains_Bees$accepted_name, method = "pa")

Klamath_Mountains_Bees$ecoregion <- 'Klamath_Mountains' # Give the ecoregion a name
Coast_Range_Bees$ecoregion <- 'Coast_Range'
Central_Basin_and_Range_Bees$ecoregion <- 'Central_Basin_and_Range'
Mojave_Basin_and_Range_Bees$ecoregion <- 'Mojave_Basin_and_Range'
Cascades_Bees$ecoregion <- 'Cascades'
Sierra_Nevadas_Bees$ecoregion <- 'Sierra_Nevadas'
Cali_Coastal_Sage_Chap_Oak_Woodlands_Bees$ecoregion <- 'Cali_Coastal_Sage_Chap_Oak_Woodlands'
Central_Cali_Valley_Bees$ecoregion <- 'Central_Cali_Valley'
Southern_and_Baja_Cali_PineOak_Mounts_Bees$ecoregion <- 'Southern_and_Baja_Cali_PineOak_Mounts'
Northern_Basin_and_Range_Bees$ecoregion <- 'Northern_Basin_and_Range'
Sonoran_Desert_Bees$ecoregion <- 'Sonoran_Desert'
Eastern_Cascades_Slopes_and_Foothills_Bees$ecoregion <- 'Eastern_Cascades_Slopes_and_Foothills'

combined_ecoregions <- rbind(Coast_Range_Bees,Central_Basin_and_Range_Bees,Mojave_Basin_and_Range_Bees,Cascades_Bees,Sierra_Nevadas_Bees,Cali_Coastal_Sage_Chap_Oak_Woodlands_Bees, Central_Cali_Valley_Bees, Southern_and_Baja_Cali_PineOak_Mounts_Bees,Northern_Basin_and_Range_Bees, Sonoran_Desert_Bees, Klamath_Mountains_Bees,Eastern_Cascades_Slopes_and_Foothills_Bees)

combined_ecoregions$weighted_value <- 1
# Now lets use Reshape!?
melted_bees <- melt(combined_ecoregions, id = c(names(combined_ecoregions)))

combined_ecoregions2 <- combined_ecoregions %>% 
  st_drop_geometry()

site_reshaped <- reshape::cast(combined_ecoregions, accepted_name ~ ecoregion, value = 'weighted_value') # Reshape it
```

```{r}
##### Example on getting the data into incidence_raw format provided by iNEXT

library(ggplot2)
library(vegan)
library(iNEXT)

data(BCI)
t.BCI <- as.data.frame(t(BCI))

BCI.1 <- t.BCI[1:225, 1:15]
BCI.1 <- as.matrix((BCI.1 > 0) + 0)

BCI.2 <- t.BCI[1:225, 16:27]
BCI.2 <- as.matrix((BCI.2 > 0) + 0)

BCI.3 <- t.BCI[1:225, 28:30]


```

